%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Matrix factorization}\label{ch:mf}
In this Chapter we present matrix factorization models used in recommender systems 
and their relation to singular vector decomposition. 

\section{Model} 

As it was mentioned in Chapter \ref{ch:rec_sys}, our goal is to estimate the missing element of the 
score matrix $S\in\mathbb{R}^{n\times m}$ with the product of two dense, low dimension 
matrix. Let these two matrices be $P\in\mathbb{R}^{n\times k}$ and 
$Q\in\mathbb{R}^{k\times m}$ and denote the approximation of matrix $S$ with 
$\hat{S}=PQ$.

Our prediction for a given user $u$ and item $i$ pair is:
\[\hat{s}_{ui}=p_{u}q_{i},\]

where $p_u$ and $q_i$, denote $u^{th}$ row  of $P$ and  $i^{th}$ column of $Q$
respectively. We call matrix $P$ user factors because each row  of the $P$ belongs 
to a user and similarly matrix $Q$ is called item factors. 

\section{Optimizing the factorization}
In general, we measure the quality of the approximation with a loss function $L$. 
A loss function maps model parameters to a real number. In case of matrix factorization, these 
parameter values are the factor matrices.

A frequently used loss function is the mean square error on the known $s_{u,i}$ values 
of the matrix $S$,

\[L(S,P;Q)=\sum_{(u,i)}(s_{u,i}-p_{u}q_{i})^2 .\]

Our objective is to minimize the loss function $L$ with a learning algorithm.

\subsection{Learning with stochastic gradient descent}
Stohastic gradient descent assumes that $L$ is a differentiable function \footnote{
This function is mainly MSE}. The concept behind SGD is the following:
\begin{itemize}
\item Starting from the actual model parameters $\hat{\theta}$, we determine the 
gradient \footnote{Gradient is the steepest direction in the given point.} of 
the loss function $L$ with respect to $\hat{\theta}$
\[\nabla L = \frac{\partial L}{\partial \hat{\theta}}.\]

\item Using the gradient vector, we update the parameters by moving towards the 
opposite of the gradient,

\[ \hat{\theta}_{n+1}=\hat{\theta}_n - \mu \nabla L ,\]

where $\mu$ is the \emph{learning rate}, a parameter of the algorithm. 
\end{itemize}

Applying this idea to improve the prediction for matrix $S$:

\begin{algorithm}[H]
  \KwData{Elements of matrix $S$}
  \KwResult{Factor matrices $P$ and $Q$}
    Initialize $P$ and $Q$ matrices with random values\;
  \While{termination condition($L(S,P_n;Q_n)$)}{
      Select a random $S_{ui}$\;
      Compute $\frac{\partial L}{\partial \hat{p}_{u}}$\;
      Compute $\frac{\partial L}{\partial \hat{q}_{i}}$ \;
      $\hat{p}_{u}\leftarrow \hat{p}_{u}-\mu \frac{\partial}{\partial \hat{p}_{u}} L$\;
      $\hat{q}_{u}\leftarrow \hat{q}_{u}-\mu \frac{\partial}{\partial \hat{q}_{u}} L$\;
  }
  \Return $P,Q$
  \caption{SGD to factorize matrices}
\end{algorithm}


In general, loss functions assembled from a score error minimalization part and 
a model complexity regularization part. If we would use only the score error 
minimalization part, the model may overfit.

Frequently use loss function in recommender systems is 

\[L(S,P;Q)=\sum_{(u,i)}(s_{ui}-p_u q_i)^2 + \lambda (\|p_u\|^2+\|q_u\|^2).\]

This loss function minimizes the difference between the recommended and the actual score in MSE 
and the squared sum of the length of the factors. $\lambda$ is a nonnegative, finite
parameter of the function, the regularization rate. 

In case of the above detailed loss function, the algorithm iterative steps of the algorithm 
becomes the following

\[ \hat{p}_{u}\leftarrow \hat{p}_{u}+\mu \left(2\left(s_{ui}-p_u q_i\right) q_i - \lambda p_u\right),\]
\[\hat{q}_{i}\leftarrow \hat{q}_{i}+\mu \left(2\right(s_{ui}-p_u q_i\left)p_u - \lambda q_i\right) .\]

Note that when we update $q_i$, we use the $p_u$ from the previous iteration, instead of
the previous step.

\subsection{Matrix factorization with alternating least squares}

%As we saw in \ref{sec:model}, our goal is to find the $P$ and $Q$ matrices minimizing \ref{eq:mse}.
In this part we saw another iterative approach to factorize a matrix in order to predict by the mentioned
\ref{sec:model} model. We use a objective function slightly different from \ref{eq:mse}
\[ L_{w}(S,P;Q)=\sum_{(u,i)}c_{u,i}(s_{u,i}-p_{u}q_{i})^2, \]
with $c_{u,i}\geq0$, we can put different weight on different user-item pairs depending on their relevance.
We can distinguish the events by their source, we weight them with $c_{u,i}=c^+$ and $c_{u,i}=c^-$, in
case of  an \emph{implicit} and \emph{explicit} event respectively \footnote{In practice, usually 
$c^{+}=1$ and $c^{-}=0$}. 

The key idea is the following \cite{takacs2012alternating}:

\begin{algorithm}[H]
    Fill $Q_0$ with small random values. \\
    \For{$i$ in $1:N$}{
        Compute the $P_i$ matrix that minimizes $L_{w}(S,P_i;Q_{i-1})$\\
        Compute the $Q_i$ matrix that minimizes $L_{w}(S,P_i;Q_i)$
    }
  \Return $P,Q$
  \caption{ALS to factorize matrices}
\end{algorithm}
